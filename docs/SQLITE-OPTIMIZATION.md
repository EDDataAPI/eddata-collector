# SQLite Performance-Optimierung

## Aktuelle Situation

**Datenbankgr√∂√üe:** ~500MB (klein f√ºr SQLite - kann TB handhaben!)  
**Workload:** 90% Reads, 10% Writes (ideal f√ºr SQLite)  
**Deployment:** Docker Container mit 4GB Memory Limit  
**Storage:** SSD (optimal f√ºr Random Access)  

**Bereits implementiert:**
- ‚úÖ WAL Mode (Write-Ahead Logging)
- ‚úÖ Snapshots f√ºr Stats-Generierung
- ‚úÖ Indexes auf wichtigen Spalten
- ‚úÖ ANALYZE f√ºr Query-Optimizer
- ‚úÖ 1GB SQLite Cache (passt perfekt in 4GB Container)
- ‚úÖ Memory-Mapped I/O (2GB)

## Warum SQLite beibehalten?

| Vorteil | Details |
|---------|---------|
| **Geschwindigkeit** | 100,000+ reads/sec, <1ms Latenz |
| **Einfachheit** | Eine Datei, kein Server |
| **Zero Maintenance** | Kein Tuning, kein Monitoring |
| **ACID** | Vollst√§ndige Transaktionssicherheit |
| **Embedded** | Kein Netzwerk-Overhead |

**MongoDB w√ºrde die Performance verschlechtern, nicht verbessern!**

## Docker-spezifische √úberlegungen

### Memory-Limits und Cache-Size

**Aktuelles Setup:**
- Container Memory Limit: **4GB**
- SQLite Cache: **1GB** (25% des Limits - optimal!)
- Node.js Heap: **4GB** (`--max-old-space-size=4096`)
- OS + Buffers: **~1GB**

**Memory-Verteilung im Container:**
```
Total: 4GB
‚îú‚îÄ Node.js Heap: ~1.5GB (runtime)
‚îú‚îÄ SQLite Cache:  1.0GB (db cache)
‚îú‚îÄ OS Page Cache: 1.0GB (mmap + buffers)
‚îî‚îÄ Overhead:      0.5GB (system)
```

**Warum 1GB Cache perfekt ist:**
- Bei 500MB DB passt fast die gesamte DB in den Cache
- L√§sst genug RAM f√ºr Node.js und OS-Cache
- Verhindert OOM-Kills im Container

### Volume Performance

**Docker Volumes auf SSD:**
- ‚úÖ Named Volumes (`eddata-prod-data`) = native Performance
- ‚úÖ Direkter SSD-Zugriff, kein Overhead
- ‚úÖ Memory-Mapped I/O funktioniert optimal

**Bind Mounts vs Named Volumes:**
```yaml
# ‚ùå LANGSAMER (Bind Mount, vor allem auf Windows/Mac)
volumes:
  - ./eddata-data:/app/eddata-data

# ‚úÖ SCHNELLER (Named Volume, native Performance)
volumes:
  - eddata-prod-data:/app/eddata-data
```

**Dein Setup verwendet Named Volumes = Optimal!** ‚úÖ

### WAL-Mode in Docker

**Wichtig f√ºr Container-Restarts:**
- WAL-Dateien (`.db-wal`) bleiben in Volume erhalten
- Kein Datenverlust bei Container-Restart
- Checkpoint l√§uft automatisch bei Shutdown

**Optimierung:**
```javascript
// Bereits implementiert in lib/db/index.js
db.pragma('journal_mode = WAL')
db.pragma('synchronous = NORMAL')  // Sicher mit WAL, schneller als FULL
db.pragma('wal_autocheckpoint = 1000') // Checkpoint alle 1000 Pages
```

## Weitere Optimierungen

### 1. Cache-Gr√∂√üe erh√∂hen

**Aktuell:** Default (~2000 pages = ~8MB)  
**Optimal:** 250,000 pages = ~1GB RAM Cache

```javascript
// lib/db/index.js
db.pragma('cache_size = -1000000')  // -1000000 = 1GB (negative = KB)
db.pragma('temp_store = MEMORY')    // Temp tables in RAM
db.pragma('mmap_size = 2147483648') // 2GB Memory-Mapped I/O
```

**Ergebnis:** 2-10x schnellere Queries f√ºr h√§ufig genutzte Daten

### 2. Zus√§tzliche Indexes

Analysiere h√§ufige Queries und f√ºge Composite Indexes hinzu:

```javascript
// lib/db/trade-db.js - Beispiel f√ºr optimierte Commodity-Queries
function ensureIndexes () {
  const db = getDatabase()
  
  // Existing indexes
  db.exec('CREATE INDEX IF NOT EXISTS commodities_commodityName ON commodities (commodityName)')
  db.exec('CREATE INDEX IF NOT EXISTS commodities_marketId ON commodities (marketId)')
  
  // NEW: Composite indexes for common query patterns
  db.exec('CREATE INDEX IF NOT EXISTS commodities_updated_recent ON commodities (updatedAtDay DESC, commodityName)')
  db.exec('CREATE INDEX IF NOT EXISTS commodities_price_lookup ON commodities (commodityName, buyPrice, sellPrice) WHERE buyPrice > 0')
  db.exec('CREATE INDEX IF NOT EXISTS commodities_stock_demand ON commodities (commodityName, stock, demand) WHERE stock > 0 OR demand > 0')
  
  // Covering index for ticker queries (all columns in index)
  db.exec(`CREATE INDEX IF NOT EXISTS commodities_ticker_covering ON commodities 
           (commodityName, buyPrice, sellPrice, stock, demand, updatedAt) 
           WHERE buyPrice > 0 AND sellPrice > 0`)
  
  db.exec('ANALYZE')
}
```

### 3. Query-Optimierungen

**Statt:**
```javascript
// Slow: Multiple queries
const stations = db.prepare('SELECT * FROM stations').all()
const filtered = stations.filter(s => s.updatedAt > yesterday)
```

**Besser:**
```javascript
// Fast: Single optimized query
const filtered = db.prepare(`
  SELECT * FROM stations 
  WHERE updatedAt > ? 
  ORDER BY updatedAt DESC
`).all(yesterday)
```

**Noch besser mit Prepared Statements:**
```javascript
// Reuse prepared statement (10x faster bei wiederholten Aufrufen)
const getRecentStmt = db.prepare(`
  SELECT * FROM stations 
  WHERE updatedAt > ? 
  ORDER BY updatedAt DESC
`)
// Cache this in module scope, reuse multiple times
const filtered = getRecentStmt.all(yesterday)
```

### 4. Partitionierung nach Datum (Optional)

F√ºr die Trade DB, die stark w√§chst:

```sql
-- Separate table for old trades (read-only, highly compressed)
CREATE TABLE commodities_archive (
  commodityName TEXT,
  marketId INT,
  -- ... fields
  archivedAt TEXT
) WITHOUT ROWID;

-- Keep only last 90 days in main table
-- Move older to archive monthly
```

### 5. Read Replicas (Falls n√∂tig)

F√ºr sehr hohe Read-Last:

```bash
# Erstelle Read-Only Copy f√ºr API
cp eddata-data/trade.db eddata-data/trade-readonly.db
cp eddata-data/trade.db-wal eddata-data/trade-readonly.db-wal

# API √∂ffnet readonly
const tradeDb = new SqliteDatabase('trade-readonly.db', { readonly: true })
```

**Vorteil:** API blockiert Collector nie, beide laufen parallel

### 6. SSD / NVMe verwenden ‚úÖ

**Status:** ‚úÖ Bereits vorhanden!

Mit SSD profitierst du optimal von den Cache-Optimierungen:

| Storage | Random Read IOPS | Latenz | SQLite Performance |
|---------|-----------------|---------|-------------------|
| HDD 7200rpm | 100-200 | 5-10ms | Baseline |
| **SATA SSD** (aktuell) | 10,000-90,000 | 0.1-0.3ms | **10-50x schneller** ‚úÖ |
| NVMe SSD (optional) | 100,000-500,000 | 0.02-0.05ms | 100-200x schneller |

**Mit SSD + Cache-Optimierungen:**
- Memory-Mapped I/O ist extrem effizient (OS cached automatisch auf SSD)
- Random Access Patterns (Indexes) sind kein Problem
- Gro√üe Cache-Size (1GB) ve (Docker-optimiert)
- ‚úÖ Docker Container: 4GB Memory Limit (perfekt f√ºr Workload)
- ‚úÖ Named Volumes auf SSD (native Performance)
- ‚úÖ SQLite Cache: 1GB (25% von 4GB - optimal!)
- ‚úÖ temp_store = MEMORY
- ‚úÖ mmap_size: 2GB (nutzt OS Page Cache)
- ‚úÖ Composite Indexes
- ‚úÖ WAL Mode mit auto-checkpoint
- ‚úÖ Node.js Heap: 4GB

**Dein Docker-Setup ist bereits optimal konfiguriert!** üéØiteDatabase(EDDATA_TRADE_DB, {
  verbose: (sql, time) => {
    if (time > 100) { // Log slow queries > 100ms
      console.warn(`SLOW QUERY (${time}ms):`, sql)
    }
  }
})
```

## Performance Messungen

### Vor Optimierungen (Baseline)
```bash
# Trade DB Query Performance
time npm run stats:commodity
# Real: 2m 30s
```

### Nach Cache-Optimierungen
```bash
# Expected: ~30s (5x faster)
```

### Mit Read Replica
```bash
# Expected: ~15s (10x faster, kein Lock-Contention)
```

## MongoDB Vergleich (Warum NICHT wechseln)

| Feature | SQLite (optimiert) | MongoDB |
|---------|-------------------|---------|
| Query Time | 0.1-5ms | 10-50ms |
| Setup | 0 (eingebaut) | Separate Server |
| Memory | 50-200MB | 500MB-2GB |
| Latenz | Sub-millisecond | 5-50ms (Netzwerk) |
| Transactions | ACID, sofort | Eventual Consistency |
| Schema Changes | Einfach | Migration Scripts |
| Backup | Eine Datei kopieren | mongodump/mongorestore |
| Cost | Free | $0-200/Monat Cloud |

## Wann MongoDB Sinn macht

MongoDB ist sinnvoll wenn:
- ‚ùå Hochgradig denormalisierte Dokumente (nicht dein Fall - relational!)
- ‚ùå Horizontale Skalierung √ºber mehrere Server (nicht n√∂tig bei 500MB)
- ‚ùå Geo-Spatial Queries mit komplexen Shapes (nicht relevant)
- ‚ùå Text-Search √ºber gro√üe Dokumente (nicht dein Use-Case)

**F√ºr Elite Dangerous Data:** Alle Kriterien sind ‚ùå - SQLite ist ideal!

## Empfohlene Implementierung

### ‚úÖ Bereits implementiert
- ‚úÖ SSD Storage (optimal f√ºr Random Access)
- ‚úÖ Cache-Size auf 1GB erh√∂ht
- ‚úÖ temp_store = MEMORY
- ‚úÖ mmap_size aktiviert (2GB)
- ‚úÖ Composite Indexes hinzugef√ºgt
- ‚úÖ WAL Mode aktiv

### üéØ N√§chste Schritte (optional)

1. **Bei Bedarf** (wenn Performance nicht reicht):
   - Slow Query Logging aktivieren (nur temp in Dev)
   - Prepared Statements cachen in oft genutzten Queries
   
2. **Sp√§ter** (bei starkem Wachstum >50GB):
   - Read Replica f√ºr API (keine Lock-Contention)
   - Partitionierung f√ºr alte Trades (>90 Tage)
   - Archive-Strategie

**Mit SSD + aktuellen Optimierungen solltest du bereits Top-Performance haben!**

## Monitoring

### In Docker Container

```bash
# Container Memory-Nutzung pr√ºfen
docker stats eddata-collector-prod

# In Container: DB-Gr√∂√üe pr√ºfen
docker exec eddata-collector-prod du -sh /app/eddata-data/*.db*

# WAL-Gr√∂√üe √ºberwachen (sollte < 10% der DB sein)
docker exec eddata-collector-prod ls -lh /app/eddata-data/*.db-wal

# Container Logs f√ºr Performance-Probleme
docker logs eddata-collector-prod --tail 100 | grep -i "slow\|error\|timeout"

# Volume-Gr√∂√üe pr√ºfen
docker system df -v | grep eddata-prod-data
```

### Performance-Metriken

```bash
# Index-Nutzung pr√ºfen
docker exec eddata-collector-prod sqlite3 /app/eddata-data/trade.db \
  "EXPLAIN QUERY PLAN SELECT * FROM commodities WHERE commodityName='Gold'"

# Cache-Hit-Rate (via PRAGMA)
docker exec eddata-collector-prod sqlite3 /app/eddata-data/trade.db \
  "PRAGMA cache_spill; PRAGMA cache_size;"
```

### Docker Resource Limits

```yaml
# docker-compose.production.yml
deploy:
  resources:
    limits:
      cpus: '2.0'      # 2 CPU cores max
      memory: 4G       # Perfekt f√ºr 1GB SQLite Cache
    reservations:
      cpus: '1.0'      # Garantiert 1 core
      memory: 2G       # Garantiert 2GB
```

**Wenn Memory-Probleme auftreten:**
1. Pr√ºfe `docker stats` f√ºr OOM
2. Reduziere Cache auf 512MB wenn n√∂tig
3. Erh√∂he Memory Limit auf 6GB f√ºr mehr Headroom

## Fazit

**SQLite ist f√ºr deinen Use-Case optimal!** Mit den implementierten Optimierungen:

‚úÖ **SSD Storage** = 10-50x schnellere Random Reads  
‚úÖ **1GB Cache** = Meiste Queries ohne Disk-I/O  
‚úÖ **Memory-Mapped I/O** = Zero-Copy OS-Cache  
‚úÖ **Composite Indexes** = Optimiert f√ºr h√§ufige Queries  

**Erwartete Performance:**
- Commodity Queries: **5-10x schneller**
- Stats-Generierung: **3-5x schneller**  
- API Response: **50-100ms ‚Üí 5-20ms**

**MongoDB w√ºrde Performance VERSCHLECHTERN:**
- Netzwerk-Latenz: +5-50ms pro Query
- Serialization-Overhead: JSON ‚Üî BSON
- Setup-Komplexit√§t: Separate Server, Monitoring, etc.

**Faustregel:** Erst zu einem anderen DB-System wechseln wenn SQLite nicht mehr gen√ºgt. Bei read-heavy Workloads auf SSD und <100GB Daten ist das praktisch **nie** der Fall.

**Dein Setup (SSD + Optimierungen) ist bereits Enterprise-Grade f√ºr diesen Use-Case!** üöÄ
